---
title: "Section 5: Analysis Techniques for Conjoint Analysis"
output:
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
    css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
```

# 5. Analysis Techniques - Part 1: Conjoint Analysis

## Count analysis

```{r conjoint-count-analysis}
# Create sample data for this section
set.seed(123)
conjoint_data_long <- tibble(
  resp_id = rep(1:3, each = 12),
  task_id = rep(rep(1:4, each = 3), 3),
  alt_id = rep(1:3, 12),
  choice = rep(0, 36),
  brand = sample(c("Apple", "Samsung", "Google", "Xiaomi"), 36, replace = TRUE),
  price = sample(c("$400", "$700", "$1000"), 36, replace = TRUE),
  battery = sample(c("15 hours", "20 hours", "25 hours"), 36, replace = TRUE),
  camera = sample(c("16 MP", "64 MP", "128 MP"), 36, replace = TRUE)
)

# Simulate choices (one choice per task)
for (r in unique(conjoint_data_long$resp_id)) {
  for (t in unique(conjoint_data_long$task_id)) {
    idx <- which(conjoint_data_long$resp_id == r & conjoint_data_long$task_id == t)
    chosen <- sample(idx, 1)
    conjoint_data_long$choice[chosen] <- 1
  }
}

# Simple count analysis for conjoint
conjoint_counts <- conjoint_data_long %>%
  filter(choice == 1) %>%
  group_by(brand) %>%
  summarize(count = n(), .groups = "drop") %>%
  mutate(percentage = count / sum(count) * 100)

# Visualize counts
ggplot(conjoint_counts, aes(x = reorder(brand, -percentage), y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Brand Preference Based on Choice Counts",
       x = "Brand", y = "Percentage of Choices (%)") +
  theme_minimal()
```

::: {.interpretation}
The chart above shows a simple count analysis for brand preference. It displays the percentage of times each brand was chosen across all choice tasks. This is a basic analysis that doesn't account for the influence of other attributes or the experimental design.
:::

```{r conjoint-count-by-attribute}
# Count analysis for all attributes
conjoint_counts_all <- list()

for (attr in c("brand", "price", "battery", "camera")) {
  counts <- conjoint_data_long %>%
    filter(choice == 1) %>%
    group_by_at(attr) %>%
    summarize(count = n(), .groups = "drop") %>%
    mutate(percentage = count / sum(count) * 100,
           attribute = attr)
  
  conjoint_counts_all[[attr]] <- counts
}

# Combine all counts
all_counts <- bind_rows(conjoint_counts_all)

# Visualize counts for all attributes
ggplot(all_counts, aes(x = reorder(interaction(attribute, get(attribute)), -percentage), 
                       y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  facet_wrap(~ attribute, scales = "free_x") +
  labs(title = "Preference Counts by Attribute Level",
       x = "Attribute Level", y = "Percentage of Choices (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Multinomial Logit (MNL)

```{r conjoint-mnl-setup, message=FALSE, warning=FALSE}
# Note: This section would normally use the mlogit package
# We'll create a simplified version that doesn't require external packages

# Function to create dummy variables for categorical variables
create_dummies <- function(data, var_name) {
  levels <- unique(data[[var_name]])
  result <- matrix(0, nrow = nrow(data), ncol = length(levels))
  colnames(result) <- paste0(var_name, levels)
  
  for (i in 1:length(levels)) {
    result[data[[var_name]] == levels[i], i] <- 1
  }
  
  return(as.data.frame(result))
}

# Create dummy variables for all attributes
conjoint_dummies <- conjoint_data_long %>%
  select(resp_id, task_id, alt_id, choice)

for (attr in c("brand", "price", "battery", "camera")) {
  dummies <- create_dummies(conjoint_data_long, attr)
  conjoint_dummies <- cbind(conjoint_dummies, dummies)
}

# Display the first few rows of the dummy-coded data
knitr::kable(head(conjoint_dummies[, 1:10]), caption = "Dummy-Coded Conjoint Data (First 10 Columns)")
```

```{r conjoint-mnl-simplified, message=FALSE, warning=FALSE}
# Simplified logistic regression as a stand-in for MNL
# In a real analysis, you would use mlogit package

# Create a simplified coefficient table for demonstration
set.seed(123)
coef_names <- names(conjoint_dummies)[5:ncol(conjoint_dummies)]
coef_values <- runif(length(coef_names), -1, 1)
names(coef_values) <- coef_names

# Create a summary table
summary_table <- data.frame(
  Coefficient = names(coef_values),
  Estimate = coef_values,
  StdError = runif(length(coef_values), 0.1, 0.5)
)

summary_table$z_value <- summary_table$Estimate / summary_table$StdError
summary_table$p_value <- 2 * (1 - pnorm(abs(summary_table$z_value)))
summary_table$significance <- ifelse(summary_table$p_value < 0.05, "*", "")

knitr::kable(summary_table, digits = 3, 
             caption = "Simulated Multinomial Logit Model Results")
```

::: {.interpretation}
The table above shows simulated results of a multinomial logit (MNL) model for the conjoint data. Each coefficient represents the part-worth utility for that attribute level. Positive values indicate higher preference, while negative values indicate lower preference. The significance column (*) indicates whether the coefficient is statistically significant at the 5% level.

In a real analysis, you would use the `mlogit` package to estimate these coefficients properly.
:::

```{r conjoint-mnl-visualization}
# Visualize MNL coefficients
coef_df <- data.frame(
  attribute_level = names(coef_values),
  coefficient = coef_values,
  attribute = gsub("([a-z]+).*", "\\1", names(coef_values))
)

ggplot(coef_df, aes(x = reorder(attribute_level, coefficient), y = coefficient)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  facet_wrap(~ attribute, scales = "free_x") +
  coord_flip() +
  labs(title = "Part-Worth Utilities from MNL Model",
       x = "Attribute Level", y = "Utility") +
  theme_minimal()
```

## Market simulation / share of preference

```{r conjoint-simulation-analysis}
# Define some product profiles for simulation
profiles <- data.frame(
  profile = c("Premium", "Mid-range", "Budget", "Value"),
  brand = c("Apple", "Samsung", "Xiaomi", "Google"),
  price = c("$1000", "$700", "$400", "$700"),
  battery = c("25 hours", "20 hours", "15 hours", "25 hours"),
  camera = c("128 MP", "64 MP", "16 MP", "64 MP")
)

# Function to calculate utilities for profiles using our simulated coefficients
calculate_utilities <- function(profiles, coefs) {
  # Initialize utility vector
  utilities <- numeric(nrow(profiles))
  
  # Calculate utilities for each profile
  for (i in 1:nrow(profiles)) {
    utility <- 0
    
    # Add brand utility
    brand_var <- paste0("brand", profiles$brand[i])
    if (brand_var %in% names(coefs)) {
      utility <- utility + coefs[brand_var]
    }
    
    # Add price utility
    price_var <- paste0("price", profiles$price[i])
    if (price_var %in% names(coefs)) {
      utility <- utility + coefs[price_var]
    }
    
    # Add battery utility
    battery_var <- paste0("battery", profiles$battery[i])
    if (battery_var %in% names(coefs)) {
      utility <- utility + coefs[battery_var]
    }
    
    # Add camera utility
    camera_var <- paste0("camera", profiles$camera[i])
    if (camera_var %in% names(coefs)) {
      utility <- utility + coefs[camera_var]
    }
    
    utilities[i] <- utility
  }
  
  return(utilities)
}

# Calculate utilities and shares
utilities <- calculate_utilities(profiles, coef_values)
shares <- exp(utilities) / sum(exp(utilities)) * 100

# Create results table
simulation_results <- profiles
simulation_results$utility <- utilities
simulation_results$share <- shares

# Display results
knitr::kable(simulation_results, digits = 2, 
             caption = "Market Simulation Results")

# Visualize market shares
ggplot(simulation_results, aes(x = reorder(profile, -share), y = share)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Predicted Market Shares",
       x = "Product Profile", y = "Share of Preference (%)") +
  theme_minimal()
```

::: {.interpretation}
The chart above shows the predicted market shares for four different smartphone profiles based on the simulated MNL model. The shares are calculated using the logit rule, which converts utilities to probabilities. This simulation helps predict how different product configurations might perform in the market.
:::
